{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfLs_UJQvTE1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u7IStj6uvTJN"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "             \"Three years later, the coffin was still full of Jello.\",\n",
        "             \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
        "             \"The person box was packed with jelly many dozens of months later.\",\n",
        "             \"Standing on one's head at job interviews forms a lasting impression.\",\n",
        "             \"It took him a month to finish the meal.\",\n",
        "             \"Finishing the meal took him 3 weeks.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6_zQDuzvTRp"
      },
      "outputs": [],
      "source": [
        "model_name = 'sentence-transformers/bert-base-nli-mean-tokens'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4QMUKcWvTT7"
      },
      "outputs": [],
      "source": [
        "def compute_tokens(sentences, tokenizer):\n",
        "    \n",
        "    input_ids = []\n",
        "    attention_mask = []\n",
        "    for sentence in sentences:\n",
        "        sentence_encoding = tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            max_length=128,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        input_ids.append(sentence_encoding['input_ids'][0])\n",
        "        attention_mask.append(sentence_encoding['attention_mask'][0])\n",
        "    \n",
        "    input_ids = torch.stack(input_ids)\n",
        "    attention_mask = torch.stack(attention_mask)\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8j79hrAvTWO"
      },
      "outputs": [],
      "source": [
        "def compute_sentence_vector(tokens, model):\n",
        "    \n",
        "    last_hidden_state, pooled_output = model(**tokens, return_dict=False)\n",
        "    '''\n",
        "    Now let's apply mean pooling on last_hidden_state vector of shape torch.Size([6,128,768])\n",
        "    to convert it into meaningful sentence embedding.\n",
        "\n",
        "    For this we need to create a sentence vector by multiplying the attention_mask\n",
        "    with last_hidden_state so that we ignore non-real tokens i.e. ignore padding tokens. \n",
        "    \n",
        "    The final sentence vector will have 768 embeddings for those\n",
        "    words where there was 1 else 0 = padding tokens.\n",
        "    In order to multiply, we need to expand attention_mask dim by 1 so that both becomes [6,128,768].\n",
        "    '''    \n",
        "    attention_mask = tokens['attention_mask'].unsqueeze(-1).expand(last_hidden_state.shape).float()\n",
        "    masked_embeddings = last_hidden_state * attention_mask \n",
        "\n",
        "    '''\n",
        "    This pooling operation will take the mean of all token embeddings and compress them into a \n",
        "    single 768 vector space — creating a ‘sentence vector’.\n",
        "\n",
        "    At the same time, we can’t just take the mean activation as is. We need to consider \n",
        "    null padding tokens (which we should not include).\n",
        "    '''\n",
        "    summed = torch.sum(masked_embeddings, dim=1)\n",
        "    counts = torch.clamp(attention_mask.sum(dim=1), min=1e-9) \n",
        "    mean_pooled_embedding = summed / counts\n",
        "    return mean_pooled_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "nBswqqpWvTYm"
      },
      "outputs": [],
      "source": [
        "def compute_similarity(sentences, tokenizer, model):\n",
        "    \n",
        "    sentences_tokens = compute_tokens(sentences, tokenizer)\n",
        "    sentences_embeddings = compute_sentence_vector(sentences_tokens, model)\n",
        "    sentences_embeddings_detached = sentences_embeddings.detach().numpy()\n",
        "    similarity_scores = cosine_similarity([sentences_embeddings_detached[0]], sentences_embeddings_detached[1:])\n",
        "\n",
        "    d = {\n",
        "        'column-1': [sentences[0] for _ in range(len(sentences)-1)],\n",
        "        'column-2': [sent for sent in sentences[1:]],\n",
        "        'scores': similarity_scores[0]\n",
        "    }\n",
        "\n",
        "    output = pd.DataFrame(data=d)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "BsOqTYM_vTbq"
      },
      "outputs": [],
      "source": [
        "output = compute_similarity(sentences, tokenizer, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4UbkWdKUvTgQ",
        "outputId": "bca3fbdd-9a7e-42ed-8420-b9d7964a66e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column-1</th>\n",
              "      <th>column-2</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Three years later, the coffin was still full o...</td>\n",
              "      <td>The fish dreamed of escaping the fishbowl and ...</td>\n",
              "      <td>0.330889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Three years later, the coffin was still full o...</td>\n",
              "      <td>The person box was packed with jelly many doze...</td>\n",
              "      <td>0.721926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Three years later, the coffin was still full o...</td>\n",
              "      <td>Standing on one's head at job interviews forms...</td>\n",
              "      <td>0.174755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Three years later, the coffin was still full o...</td>\n",
              "      <td>It took him a month to finish the meal.</td>\n",
              "      <td>0.447096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Three years later, the coffin was still full o...</td>\n",
              "      <td>Finishing the meal took him 3 weeks.</td>\n",
              "      <td>0.579585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            column-1  ...    scores\n",
              "0  Three years later, the coffin was still full o...  ...  0.330889\n",
              "1  Three years later, the coffin was still full o...  ...  0.721926\n",
              "2  Three years later, the coffin was still full o...  ...  0.174755\n",
              "3  Three years later, the coffin was still full o...  ...  0.447096\n",
              "4  Three years later, the coffin was still full o...  ...  0.579585\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "sentence similarity using BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
